{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0fa16f",
   "metadata": {},
   "source": [
    "# Alternative to Amazon Lookout for Vision with SageMaker Algorithm: Computer Vision Defect Detection Model from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d6413",
   "metadata": {},
   "source": [
    "Amazon Lookout for Vision, the AWS service designed to create customized artificial intelligence and machine learning (AI/ML) computer vision models for automated quality inspection, will be discontinuing on October 31, 2025. As part of this transition, the Lookout for Vision (LFV) team has published their algorithm for use within Amazon SageMaker, ensuring continuity and expanded possibilities for users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e50cd",
   "metadata": {},
   "source": [
    "This notebook guides you through the process of:\n",
    "\n",
    "1. Subscribe to the LFV-published algorithm in Amazon SageMaker\n",
    "1. Train an image classification model using this algorithm, which maintains the same training logic as the existing LFV service\n",
    "1. Train an image segmentation model using this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f77b9a",
   "metadata": {},
   "source": [
    "By following this guide, you'll be able to seamlessly incorporate LFV's proven computer vision capabilities into your SageMaker workflows. Whether you're transitioning existing LFV projects or starting new ones, this notebook will help ensure your automated quality inspection workflows remain uninterrupted beyond the LFV service discontinuation date. \n",
    "This sample notebook shows you how to train a custom ML model using [Computer Vision Defect Detection Model](https://aws.amazon.com/marketplace/pp/prodview-j72hhmlt6avp6) from AWS Marketplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120de4f",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6532a22",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "1. Note: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using **Amazon SageMaker**.\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "   \n",
    "   A. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
    "   \n",
    "        a. aws-marketplace:ViewSubscriptions\n",
    "        b. aws-marketplace:Unsubscribe\n",
    "        c. aws-marketplace:Subscribe\n",
    "   \n",
    "   B: or your AWS account has a subscription to: [Computer Vision Defect Detection Model](https://aws.amazon.com/marketplace/pp/prodview-j72hhmlt6avp6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968c7ea",
   "metadata": {},
   "source": [
    "### Subscribe to the algorithm\n",
    "\n",
    "To subscribe to the algorithm:\n",
    "\n",
    "1. Open the algorithm listing page: [Computer Vision Defect Detection Model](https://aws.amazon.com/marketplace/pp/prodview-j72hhmlt6avp6).\n",
    "1. On the AWS Marketplace listing, click on Continue to subscribe button.\n",
    "1. On the Subscribe to this software page, review and click on \"Accept Offer\" if you agree with EULA, pricing, and support terms.\n",
    "1. Once you click on Continue to configuration button and then choose a region, you will see a Product Arn. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the algorithm name and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change this to use subscribed SageMaker algorithm\n",
    "algorithm_name = \"<Customer to specify the algorithm name after subscription>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a681a",
   "metadata": {},
   "source": [
    "### Initial Set Up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519c293",
   "metadata": {},
   "source": [
    "Set up your SageMaker environment: First, we'll import necessary libraries, set up our SageMaker session, and define key variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "# Project name would be used as part of s3 output path\n",
    "project = \"Computer-Vision-Defect-Detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d5faf",
   "metadata": {},
   "source": [
    "### Create IAM Role with SageMaker Permission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d046f",
   "metadata": {},
   "source": [
    "Then we will create an IAM role with SageMaker full access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c284ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client('iam')\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the IAM role\n",
    "role_name = \"SageMakerExecutionRole\"\n",
    "response = None\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "        Description=\"IAM role with full S3 and SageMaker access\"\n",
    "    )\n",
    "\n",
    "    sm_role_arn = response['Role']['Arn']\n",
    "    print(f\"Role created with ARN: {sm_role_arn}\")\n",
    "\n",
    "    # Attach policies for full S3 and SageMaker access\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "    )\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\"\n",
    "    )\n",
    "    print(\"Attached S3 full access and SageMaker full access\")\n",
    "except:\n",
    "    print(\"role already exists trying to get existing role\") \n",
    "    response = iam_client.get_role(\n",
    "        RoleName=role_name\n",
    "    )\n",
    "    print(\"got existing role\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b732878",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client = boto3.client('iam')\n",
    "role_name = \"SageMakerExecutionRole\"\n",
    "iam_client.get_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ad1a1",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "We will go through two examples, one for image classification model, the other one for image segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad86092",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b8f94",
   "metadata": {},
   "source": [
    "**Prepare your classification data:**\n",
    "For this step, we'll follow the data preparation guidelines as outlined in the Amazon Lookout for Vision Developer Guide (https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/getting-started.html). And we will use cookie dataset in this guide.\n",
    "\n",
    "a. Organize your images:\n",
    "Place your normal (non-defective) images in a S3 path named \"normal\".\n",
    "Place your anomalous (defective) images in a S3 path named \"anomaly\".\n",
    "\n",
    "b. Create a manifest file: The manifest file is a JSON Lines file that lists your images and their classifications. Each line in the file represents one image and contains a JSON object with the following structure:\n",
    "\n",
    "* \"source-ref\" is the S3 URI of the image\n",
    "* \"auto-label\" is 0 for normal images and 1 for anomalous images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4480c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train_class.manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2693c7",
   "metadata": {},
   "source": [
    "Upload manifest file to preferred S3 path, change \"bucket_name\" and \"object_key\" to the location you would like to store your manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"<Specify S3 bucket name>\"\n",
    "object_key = \"<Specify S3 object key>/train_class.manifest\"\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('train_class.manifest', bucket_name, object_key)\n",
    "classification_s3_path = f\"s3://{bucket_name}/{object_key}\" \n",
    "print(classification_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c88cb",
   "metadata": {},
   "source": [
    "**Create SageMaker training job:**\n",
    "Now that we have our data prepared and uploaded to S3, we can create and start the training job using the LFV published SageMaker algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "sagemaker = boto3.Session(region_name=region).client(\"sagemaker\")\n",
    "classification_training_job_name = 'defect-detection-classification-'+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019056c",
   "metadata": {},
   "source": [
    "Create SageMaker training job using subscribed algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9990c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker.create_training_job(\n",
    "    TrainingJobName=classification_training_job_name,\n",
    "    HyperParameters={\n",
    "        'ModelType': 'classification',\n",
    "        'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label',\n",
    "        'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'AlgorithmName': algorithm_name,\n",
    "        'TrainingInputMode': 'File',\n",
    "        'EnableSageMakerMetricsTimeSeries': False\n",
    "    },\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'training',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'AugmentedManifestFile',\n",
    "                    'S3Uri': classification_s3_path,\n",
    "                    'S3DataDistributionType': 'ShardedByS3Key',\n",
    "                    'AttributeNames': [\n",
    "                        'source-ref',\n",
    "                        'anomaly-label-metadata',\n",
    "                        'anomaly-label'\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'RecordIO',\n",
    "            'InputMode': 'Pipe'\n",
    "        },\n",
    "    ],\n",
    "    OutputDataConfig={'S3OutputPath': 's3://'+bucket+'/'+project+'/output'},\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.g4dn.2xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 20\n",
    "    },\n",
    "    EnableNetworkIsolation=True,\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 7200\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df326e69",
   "metadata": {},
   "source": [
    "Waiting for training job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    training_response = sagemaker.describe_training_job(\n",
    "        TrainingJobName=classification_training_job_name\n",
    "    )\n",
    "    if training_response['TrainingJobStatus'] == 'InProgress':\n",
    "        print(\".\", end='')\n",
    "    elif training_response['TrainingJobStatus'] == 'Completed':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif training_response['TrainingJobStatus'] == 'Failed':\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38efdd",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8031e",
   "metadata": {},
   "source": [
    "## Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c45eb3",
   "metadata": {},
   "source": [
    "**Prepare your segmentation data:**\n",
    "For this step, we'll follow the data preparation guidelines as outlined in the Amazon Lookout for Vision Developer Guide (https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/getting-started.html). And we will use cookie dataset in this guide.\n",
    "\n",
    "For image segmentation tasks, the data preparation process is slightly different from classification. Here's how to prepare your data for segmentation:\n",
    "\n",
    "  1. Place your original images in a S3 path e.g. \"images\".  \n",
    "  1. Place corresponding segmentation masks in a S3 path named e.g. \"masks\".\n",
    "  1. Create a manifest file: The manifest file is a JSON Lines file that lists your images and their classifications. Each line in the file represents one image and contains a JSON object with the following structure:\n",
    "  \n",
    "   * \"source-ref\" is the S3 URI of the image\n",
    "   * \"anomaly-label\" is 0 for normal images and 1 for anomalous images\n",
    "   * \"anomaly-mask-ref\" is the S3 URI of the corresponding segmentation mask (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292a4ba",
   "metadata": {},
   "source": [
    "The following JSON line shows an image with segmentation and classification information. anomaly-label-metadata contains classification information. anomaly-mask-ref and anomaly-mask-ref-metadata contain segmentation information. https://docs.aws.amazon.com/lookout-for-vision/latest/developer-guide/manifest-file-segmentation.html\n",
    "\n",
    "```\n",
    "{\n",
    "    \"source-ref\": \"s3://path-to-image\",\n",
    "    \"anomaly-label\": 1,\n",
    "    \"anomaly-label-metadata\": {\n",
    "        \"class-name\": \"anomaly\",\n",
    "        \"creation-date\": \"2021-10-12T14:16:45.668\",\n",
    "        \"human-annotated\": \"yes\",\n",
    "        \"job-name\": \"labeling-job/classification-job\",\n",
    "        \"type\": \"groundtruth/image-classification\",\n",
    "        \"confidence\": 1\n",
    "    },\n",
    "    \"anomaly-mask-ref\": \"s3://path-to-image\",\n",
    "    \"anomaly-mask-ref-metadata\": {\n",
    "        \"internal-color-map\": {\n",
    "            \"0\": {\n",
    "                \"class-name\": \"BACKGROUND\",\n",
    "                \"hex-color\": \"#ffffff\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"1\": {\n",
    "                \"class-name\": \"scratch\",\n",
    "                \"hex-color\": \"#2ca02c\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"2\": {\n",
    "                \"class-name\": \"dent\",\n",
    "                \"hex-color\": \"#1f77b4\",\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        },\n",
    "        \"type\": \"groundtruth/semantic-segmentation\",\n",
    "        \"human-annotated\": \"yes\",\n",
    "        \"creation-date\": \"2021-11-23T20:31:57.758889\",\n",
    "        \"job-name\": \"labeling-job/segmentation-job\"\n",
    "    }\n",
    "}                        \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6251f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat train_segmentation.manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19efd51",
   "metadata": {},
   "source": [
    "Upload manifest file to preferred S3 path, change \"bucket_name\" and \"object_key\" to the location you would like to store your manifest file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38453a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"<Specify S3 bucket name>\"\n",
    "seg_manifest_object_key = \"<Specify S3 object key>/train_segmentation.manifest\"\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('train_segmentation.manifest', bucket_name, seg_manifest_object_key)\n",
    "segmentation_s3_path = f\"s3://{bucket_name}/{seg_manifest_object_key}\" \n",
    "print(segmentation_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e39f56",
   "metadata": {},
   "source": [
    "**Create SageMaker training job:**\n",
    "\n",
    "Start traning job for segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de783648",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_training_job_name = 'defect-detection-segmentation-'+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d291b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.Session(region_name=region).client(\"sagemaker\")\n",
    "response = sagemaker.create_training_job(\n",
    "    TrainingJobName=segmentation_training_job_name,\n",
    "    HyperParameters={\n",
    "        'ModelType': 'segmentation',\n",
    "        'TestInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref',\n",
    "        'TrainingInputDataAttributeNames': 'source-ref,anomaly-label-metadata,anomaly-label,anomaly-mask-ref-metadata,anomaly-mask-ref'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'AlgorithmName': algorithm_name,\n",
    "        'TrainingInputMode': 'File',\n",
    "        'EnableSageMakerMetricsTimeSeries': False\n",
    "    },\n",
    "    RoleArn=sm_role_arn,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'training',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'AugmentedManifestFile',\n",
    "                    'S3Uri': segmentation_s3_path,\n",
    "                    'S3DataDistributionType': 'ShardedByS3Key',\n",
    "                    'AttributeNames': [\n",
    "                        'source-ref',\n",
    "                        'anomaly-label-metadata',\n",
    "                        'anomaly-label',\n",
    "                        'anomaly-mask-ref-metadata',\n",
    "                        'anomaly-mask-ref'\n",
    "                    ],\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'RecordIO',\n",
    "            'InputMode': 'Pipe'\n",
    "        },\n",
    "    ],\n",
    "    OutputDataConfig={'S3OutputPath': 's3://'+bucket+'/'+project+'/output'},\n",
    "    EnableNetworkIsolation=True,\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.g4dn.2xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 20\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 7200\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b329ba8",
   "metadata": {},
   "source": [
    "Waiting for training job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    training_response = sagemaker.describe_training_job(\n",
    "        TrainingJobName=segmentation_training_job_name\n",
    "    )\n",
    "    if training_response['TrainingJobStatus'] == 'InProgress':\n",
    "        print(\".\", end='')\n",
    "    elif training_response['TrainingJobStatus'] == 'Completed':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif training_response['TrainingJobStatus'] == 'Failed':\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f7443",
   "metadata": {},
   "source": [
    "***********"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548a660",
   "metadata": {},
   "source": [
    "### (Optional) Run Inference on SageMaker Batch Transform Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3be329",
   "metadata": {},
   "source": [
    "We will use classification model example above to run inference with SageMaker batch transform job. First, we will create SageMaker Model Package from completed training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641b399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sagemaker.describe_training_job(TrainingJobName=classification_training_job_name)\n",
    "model_artifact = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "algorithm_name = training_job_info['AlgorithmSpecification']['AlgorithmName']\n",
    "print(model_artifact)\n",
    "print(algorithm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create SageMaker Model Package\n",
    "create_model_pkg_response = sagemaker.create_model_package(\n",
    "    ModelPackageName=f\"{classification_training_job_name}-package\",  # You can customize this name\n",
    "    SourceAlgorithmSpecification={\n",
    "        'SourceAlgorithms': [\n",
    "            {\n",
    "                'AlgorithmName': algorithm_name,\n",
    "                'ModelDataUrl': model_artifact\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"SageMaker Model package created: {create_model_pkg_response['ModelPackageArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83754e",
   "metadata": {},
   "source": [
    "Next, after we have model package, create SageMaker Model to run inference with batch transform job or host on endpoint based on your need. \n",
    "\n",
    "Batch Transform Jobs and SageMaker Endpoints are both used for inference in SageMaker but serve different purposes. Batch Transform is designed for offline inference, making predictions on large datasets stored in S3, and is ideal for bulk processing where low latency is not critical. Once the job is completed, the resources are released, making it cost-effective for sporadic workloads. SageMaker Endpoints are used for real-time inference, providing low-latency predictions suitable for applications requiring immediate responses. Endpoints remain active while deployed, making them better suited for continuous and steady traffic but potentially more costly due to ongoing resource usage.\n",
    "\n",
    "We will use batch transform job as an example in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57003be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Now you can use this model package ARN to create your model\n",
    "model_package_arn = create_model_pkg_response['ModelPackageArn']\n",
    "create_model_response = sagemaker.create_model(\n",
    "    ModelName=f\"{classification_training_job_name}-model\",  # You can customize this name\n",
    "    ExecutionRoleArn=sm_role_arn,\n",
    "    PrimaryContainer={\n",
    "        'ModelPackageName': model_package_arn\n",
    "    },\n",
    "    EnableNetworkIsolation=True, # EnableNetworkIsolation must be true for using product from AWS Marketplace.\n",
    ")\n",
    "\n",
    "print(f\"Created model: {create_model_response['ModelArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create SageMaker batch transform job\n",
    "batch_job_name = \"defect-detection-class-\"+datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "#############################################\n",
    "# Change to your input/output data S3 path  #\n",
    "#############################################\n",
    "s3_input_data = \"s3://<Specify-s3-path-to-test-images>\"\n",
    "s3_output_path = \"s3://<Specify-s3-path-to-store-transform-output>\"\n",
    "\n",
    "batch_transform_response = sagemaker.create_transform_job(\n",
    "    TransformJobName=batch_job_name,\n",
    "    ModelName=create_model_response['ModelArn'].split(\"/\")[-1],\n",
    "    MaxConcurrentTransforms=1,  # Adjust based on your workload\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': s3_input_data\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'image/jpeg',\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': s3_output_path\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.c5.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting for batch transform job to complete\n",
    "while True:\n",
    "    batch_response = sagemaker.describe_transform_job(\n",
    "        TransformJobName=batch_job_name\n",
    "    )\n",
    "    if batch_response['TransformJobStatus'] == 'InProgress':\n",
    "        print(\".\", end='')\n",
    "    elif batch_response['TransformJobStatus'] == 'Completed':\n",
    "        print(\"Completed\")\n",
    "        break\n",
    "    elif batch_response['TransformJobStatus'] == 'Failed':\n",
    "        print(\"Failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"?\", end='')\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad22cb",
   "metadata": {},
   "source": [
    "After batch transform job completed successfully, going to S3 output path specified in the job. There would be a output file format like `{image-file-name}.out`. For example, we were using `anomaly-1.jpg`, so there is a file in `s3_output_path` called `anomaly-1.jpg`. Below is the content inside the file:\n",
    "\n",
    "```\n",
    "{\"Source\": {\"Type\": \"direct\"}, \"IsAnomalous\": true, \"Confidence\": 0.9378743361326908}\n",
    "```\n",
    "\n",
    "So the result is anomaly and confidence score is 0.9378743361326908."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
